{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "349390ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "f2a17ccd",
   "metadata": {},
   "outputs": [],
   "source": [
    "### calculate a given mape for a daily df\n",
    "\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import median_absolute_error\n",
    "from sklearn.metrics import r2_score\n",
    "from sklearn.metrics import mean_squared_log_error\n",
    "\n",
    "# functions\n",
    "\n",
    "def wmape(actual, forecast):\n",
    "    # we take two series and calculate an output a wmape from it, not to be used in a grouping function\n",
    "    actual = pd.Series(actual)\n",
    "    forecast = pd.Series(forecast)\n",
    "\n",
    "    # make a series called mape\n",
    "    se_mape = abs(actual-forecast)/actual\n",
    "\n",
    "    # get a float of the sum of the actual\n",
    "    ft_actual_sum = actual.sum()\n",
    "\n",
    "    # get a series of the multiple of the actual & the mape\n",
    "    se_actual_prod_mape = actual * se_mape\n",
    "\n",
    "    # summate the prod of the actual and the mape\n",
    "    ft_actual_prod_mape_sum = se_actual_prod_mape.sum()\n",
    "\n",
    "    # float: wmape of forecast\n",
    "    ft_wmape_forecast = ft_actual_prod_mape_sum / ft_actual_sum\n",
    "    print(ft_wmape_forecast)\n",
    "    # return a float\n",
    "    return \"WMAPE\",ft_wmape_forecast\n",
    "\n",
    "def mean_absolute_percentage_error(y_true, y_pred):\n",
    "    return \"MAPE\", np.mean(np.abs((y_true - y_pred) / y_true)) * 100\n",
    "\n",
    "def mae(y_true, y_pred):\n",
    "    return \"MAE\",mean_absolute_error(y_true, y_pred)\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "    rms = mean_squared_error(y_true, y_pred, squared=False)\n",
    "    return \"RMSE\", rms\n",
    "\n",
    "def mse(y_true, y_pred):\n",
    "    mse = mean_squared_error(y_true, y_pred, squared=True)\n",
    "    return \"MSE\", mse\n",
    "\n",
    "def medae(y_true, y_pred):\n",
    "    return \"MEDAE\", median_absolute_error(y_true, y_pred)\n",
    "\n",
    "def r2(y_true, y_pred):\n",
    "    return \"R2\",r2_score(y_true, y_pred)\n",
    "\n",
    "def msle(y_true, y_pred):\n",
    "    return \"MSLE\", mean_squared_log_error(y_true, y_pred)\n",
    "\n",
    "def maape(y_true,y_pred): # https://www.sciencedirect.com/science/article/pii/S0169207016000121\n",
    "    EPSILON = 1e-10\n",
    "    return \"MAAPE\", np.mean(np.arctan(np.abs((y_true - y_pred) / (y_true + EPSILON))))\n",
    "\n",
    "### from peak challenge\n",
    "def get_peak_values_from_loadpatterm(loadpattern):\n",
    "  peakvalues = []\n",
    "  for i in range (int(len(loadpattern)/24)):\n",
    "    to_consider = loadpattern[i*24:(i+1)*24]\n",
    "    peakvalues.append(np.max(to_consider))\n",
    "  return np.array(peakvalues)\n",
    "\n",
    "def get_peak_times_from_loadpattern(loadpattern):\n",
    "    peaktimes = []\n",
    "    for i in range (int(len(loadpattern)/24)):\n",
    "        to_consider = loadpattern[i*24:(i+1)*24]\n",
    "        peaktimes.append(to_consider.tolist().index(np.max(to_consider)))\n",
    "    to_return = np.array(peaktimes)\n",
    "    to_return = to_return+1\n",
    "    return to_return\n",
    "\n",
    "\n",
    "def shape_score (actual_loadpattern,predicted_loadpattern):\n",
    "    normed_peaksurroundings_actual = []\n",
    "    normed_peaksurroundings_pred = []\n",
    "    for block_index in range (int(len(actual_loadpattern)/24)):\n",
    "        startindex= block_index*24\n",
    "        block_actual = actual_loadpattern[startindex:(block_index+1)*24]\n",
    "        peakvalue_actual = np.max(block_actual)\n",
    "        peakindex_actual  = np.where(block_actual == peakvalue_actual)[0][0]\n",
    "        normed_actual = actual_loadpattern/peakvalue_actual\n",
    "\n",
    "        block_pred = predicted_loadpattern[startindex:(block_index+1)*24]\n",
    "        peakvalue_pred = np.max(block_pred)\n",
    "        normed_pred = predicted_loadpattern/peakvalue_pred\n",
    "\n",
    "\n",
    "        normed_peaksurroundings_actual.extend(normed_actual[startindex + peakindex_actual-2:startindex +peakindex_actual+3])\n",
    "        normed_peaksurroundings_pred.extend(normed_pred[startindex+peakindex_actual-2: startindex+ peakindex_actual+3])\n",
    "    normed_peaksurroundings_actual = np.array(normed_peaksurroundings_actual)\n",
    "    normed_peaksurroundings_pred = np.array(normed_peaksurroundings_pred)\n",
    "    absolute_errors = abs(normed_peaksurroundings_actual-normed_peaksurroundings_pred)\n",
    "    return \"shape_score\", np.sum(absolute_errors)\n",
    "\n",
    "def peaktime_score(actual_peaktimes, predicted_peaktimes):\n",
    "    absolute_diffs = abs(actual_peaktimes-predicted_peaktimes)\n",
    "    total_diffs = 0\n",
    "    for diff in absolute_diffs:\n",
    "        if abs(diff)<2:\n",
    "            total_diffs = total_diffs+diff\n",
    "        elif abs(diff)<5:\n",
    "            total_diffs = total_diffs+(diff*2)\n",
    "        else:\n",
    "            total_diffs = total_diffs+(10)\n",
    "    return \"peaktime_score\", total_diffs\n",
    "\n",
    "\n",
    "def peak_mape(actual_values, forecasted_values):\n",
    "  peakvalues_actual = get_peak_values_from_loadpatterm(actual_values)\n",
    "  predictions_at_peaktime = get_peak_values_from_loadpatterm(forecasted_values)\n",
    "  return \"peak_mape\", mean_absolute_percentage_error(peakvalues_actual,predictions_at_peaktime)[1]\n",
    "\n",
    "def peak_rmse(actual_values, forecasted_values):\n",
    "  peakvalues_actual = get_peak_values_from_loadpatterm(actual_values)\n",
    "  predictions_at_peaktime = get_peak_values_from_loadpatterm(forecasted_values)\n",
    "  return \"peak_rmse\", rmse(peakvalues_actual,predictions_at_peaktime)[1]\n",
    "\n",
    "\n",
    "def peaktime_mae(actual_values, forecasted_values):\n",
    "  peaktimes_actual = get_peak_times_from_loadpattern(actual_values)\n",
    "  predictions_peaktime = get_peak_times_from_loadpattern(forecasted_values)\n",
    "  return \"peaktime_mae\", mean_absolute_error(peaktimes_actual,predictions_peaktime)\n",
    "\n",
    "def percentage_match(peaktimes_actual, predictions_peaktime):\n",
    "    if len(peaktimes_actual) != len(predictions_peaktime):\n",
    "        raise ValueError(\"Arrays must have the same length\")\n",
    "\n",
    "    count_matching = sum(1 for x, y in zip(peaktimes_actual, predictions_peaktime) if x == y)\n",
    "    total_elements = len(peaktimes_actual)\n",
    "\n",
    "    percentage = (count_matching / total_elements) * 100\n",
    "    return percentage\n",
    "\n",
    "def peaktime_accuracy(actual_values, forecasted_values):\n",
    "    peaktimes_actual = get_peak_times_from_loadpattern(actual_values)\n",
    "    predictions_peaktime = get_peak_times_from_loadpattern(forecasted_values)\n",
    "    result = percentage_match(peaktimes_actual, predictions_peaktime)\n",
    "\n",
    "    return \"peaktime_accuracy\", result\n",
    "\n",
    "# we also evaluate the metrics for the highest n-decile of true value\n",
    "def highest_decile_metric(y_true,y_pred,function,decile):\n",
    "    desired_hits = int(len(y_true)*decile)\n",
    "    ind_highest = np.argpartition(y_true, -desired_hits)[-desired_hits:]\n",
    "    top_hits_true = y_true[ind_highest]\n",
    "    top_hits_pred = y_pred[ind_highest]\n",
    "    name, res = function(top_hits_true,top_hits_pred)\n",
    "    return name+\"_decile_\"+str(decile), res\n",
    "\n",
    "# evaluation\n",
    "\n",
    "functions = [mean_absolute_percentage_error,mae,rmse,r2,peak_rmse,peaktime_mae,peaktime_accuracy]\n",
    "\n",
    "def evaluate_metrics(target_df, functions):\n",
    "    results = {}\n",
    "    for function in functions:\n",
    "        name, res = function(target_df[\"Agg Load\"].values, target_df[\"Predict\"].values)\n",
    "        results.update({name:res})\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "015ed737",
   "metadata": {},
   "outputs": [],
   "source": [
    "methods = [\"LSTM\", \"XGB\",\"Random Forest\"]\n",
    "nn_methods = [\"LSTM\"]\n",
    "\n",
    "runs = 4\n",
    "\n",
    "hh_results = pd.DataFrame()\n",
    "hp_results = pd.DataFrame()\n",
    "total_results = pd.DataFrame()\n",
    "\n",
    "hh_comparison = pd.DataFrame()\n",
    "hp_comparison = pd.DataFrame()\n",
    "total_comparison = pd.DataFrame()\n",
    "\n",
    "\n",
    "for method in methods: # first, we obtain the results of the different runs \n",
    "    \n",
    "    for run in range(1,runs+1):\n",
    "        comb = pd.DataFrame()\n",
    "        hp_df = pd.read_pickle(\"./HP \"+method+\" Results \"+str(run)+\".pkl\")\n",
    "        hh_df = pd.read_pickle(\"./HH \"+method+\" Results \"+str(run)+\".pkl\")\n",
    "        comb_df = pd.read_pickle(\"./Comb \"+method+\" Results \"+str(run)+\".pkl\")\n",
    "        if method in nn_methods:\n",
    "            hp_df.rename(columns={\"NN Forecast\":\"Predict\"},inplace=True)\n",
    "            hh_df.rename(columns={\"NN Forecast\":\"Predict\"},inplace=True)\n",
    "            comb_df.rename(columns={\"NN Forecast\":\"Predict\"},inplace=True)\n",
    "                \n",
    "        # creating df for plotting\n",
    "        #hh_comparison.index = hh_df.index\n",
    "        #hp_comparison.index = hp_df.index\n",
    "        total_comparison.index = comb_df.index\n",
    "        hh_comparison[method+\" Run \"+str(run)] = hh_df[\"Predict\"].values\n",
    "        hp_comparison[method+\" Run \"+str(run)] = hp_df[\"Predict\"].values\n",
    "        total_comparison[method+\" Run \"+str(run)] = comb_df[\"Predict\"].values\n",
    "        hh_comparison[\"Real Load\"] = hh_df[\"Agg Load\"].values\n",
    "        hp_comparison[\"Real Load\"] = hp_df[\"Agg Load\"].values\n",
    "        total_comparison[\"Real Load\"] = comb_df[\"Agg Load\"].values\n",
    "\n",
    "        hh_results[method+\" Run \"+str(run)] = evaluate_metrics(hh_df,functions)\n",
    "        hp_results[method+\" Run \"+str(run)] = evaluate_metrics(hp_df,functions)\n",
    "        total_results[method+\" Run \"+str(run)] = evaluate_metrics(comb_df,functions)\n",
    "            \n",
    "            \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "97907fe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we calculate descriptive statistics per method and create an average as ensemble model\n",
    "df_compare_rmse = pd.DataFrame()\n",
    "for method in methods:\n",
    "    filtered_cols = [x for x in total_results.columns if method in x]\n",
    "    filtered_results_hh = hh_results[filtered_cols]\n",
    "    filtered_results_hp = hp_results[filtered_cols]\n",
    "    filtered_results_comb = total_results[filtered_cols]\n",
    "    \n",
    "    df_compare_rmse[method+\" HH\"] = filtered_results_hh.T.describe()[\"RMSE\"]\n",
    "    df_compare_rmse[method+\" HP\"] = filtered_results_hp.T.describe()[\"RMSE\"]\n",
    "    df_compare_rmse[method+\" Comb\"] = filtered_results_comb.T.describe()[\"RMSE\"]\n",
    "    \n",
    "    if method in nn_methods: # build from average forecast final forecast\n",
    "        temp_hh = hh_df.copy()\n",
    "        temp_hh[\"Predict\"] = hh_comparison[filtered_cols].mean(axis=1).values\n",
    "        temp_hh.to_pickle(\"./../HH \"+method+\" Results.pkl\") \n",
    "        \n",
    "        temp_hp = hp_df.copy()\n",
    "        temp_hp[\"Predict\"] = hp_comparison[filtered_cols].mean(axis=1).values\n",
    "        temp_hp.to_pickle(\"./../HP \"+method+\" Results.pkl\") \n",
    "        \n",
    "        temp_comb = comb_df.copy()\n",
    "        temp_comb[\"Predict\"] = total_comparison[filtered_cols].mean(axis=1).values\n",
    "        temp_comb.to_pickle(\"./../Comb \"+method+\" Results.pkl\") \n",
    "        \n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "92cc1947",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>LSTM HH</th>\n",
       "      <td>1452.564509</td>\n",
       "      <td>6.327636</td>\n",
       "      <td>1447.214594</td>\n",
       "      <td>1461.475168</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM HP</th>\n",
       "      <td>2989.198882</td>\n",
       "      <td>90.291138</td>\n",
       "      <td>2908.373873</td>\n",
       "      <td>3083.380447</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LSTM Comb</th>\n",
       "      <td>3096.271956</td>\n",
       "      <td>58.887180</td>\n",
       "      <td>3014.159976</td>\n",
       "      <td>3152.671079</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB HH</th>\n",
       "      <td>1362.025453</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1362.025453</td>\n",
       "      <td>1362.025453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB HP</th>\n",
       "      <td>2817.448650</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>2817.448650</td>\n",
       "      <td>2817.448650</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>XGB Comb</th>\n",
       "      <td>3256.327808</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>3256.327808</td>\n",
       "      <td>3256.327808</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest HH</th>\n",
       "      <td>1368.292017</td>\n",
       "      <td>6.925888</td>\n",
       "      <td>1362.011511</td>\n",
       "      <td>1374.834449</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest HP</th>\n",
       "      <td>2761.412442</td>\n",
       "      <td>4.085598</td>\n",
       "      <td>2756.476246</td>\n",
       "      <td>2765.767370</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Random Forest Comb</th>\n",
       "      <td>3256.019219</td>\n",
       "      <td>10.805400</td>\n",
       "      <td>3242.943742</td>\n",
       "      <td>3269.301888</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           mean        std          min          max\n",
       "LSTM HH             1452.564509   6.327636  1447.214594  1461.475168\n",
       "LSTM HP             2989.198882  90.291138  2908.373873  3083.380447\n",
       "LSTM Comb           3096.271956  58.887180  3014.159976  3152.671079\n",
       "XGB HH              1362.025453   0.000000  1362.025453  1362.025453\n",
       "XGB HP              2817.448650   0.000000  2817.448650  2817.448650\n",
       "XGB Comb            3256.327808   0.000000  3256.327808  3256.327808\n",
       "Random Forest HH    1368.292017   6.925888  1362.011511  1374.834449\n",
       "Random Forest HP    2761.412442   4.085598  2756.476246  2765.767370\n",
       "Random Forest Comb  3256.019219  10.805400  3242.943742  3269.301888"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# showing the results for the rmse\n",
    "df_compare_rmse.T[[\"mean\",\"std\",\"min\",\"max\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23a92502",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "1bba1c7f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7797fe7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a91854db",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "203cc8ef",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "673b3c3d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74adf154",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
